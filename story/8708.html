<!doctype html><html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>人工智能将如何改变我们的生活，无论是好是坏</title><link rel="stylesheet" href="/css.css"><script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?f75329719d379998b2421a4cc2396366";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script></head><body><div id="header"><a class="site_title" href="http://www.fuzadu.com">复杂度</a></div><div><div><h2>人工智能将如何改变我们的生活，无论是好是坏</h2></div><div class="content"><img class="content_img" src="/image/4e/4eca11a4c8c5ddce6a004d9470b65759.jpg" /><p>如果你在过去一年左右的时间里一直关注媒体，你可能会得到这样的印象，人工智能的威胁来摧毁我们所有人只是个时间问题。</p><p>编者按：这与我们正常的如何操作和解释格式不同，在这种格式下，我们可以让我们的作者研究并展示一种发人深省的技术。</p><p>从“复仇者联盟：奥创纪元”(Avengers：Age of Ultron)和约翰尼·德普(Johnny Depp)的“超越恶臭节”(Fink-fest Transcendence)这样的暑期大片，到“前任机器”(Ex-Machina)或第四频道(Channel 4)热播电视剧“人”(Human)等较小的独立电影，编剧们似乎永远也听不够这些比喻，无论未来几十年人工智能最终采取什么形式，你都可以打赌，它将是地狱般的决心要给人类上一堂关于成为自己傲慢受害者的教训。</p><p>但是，这种对机器的恐惧有道理吗？在这个重要的专题中，我们将从当今在该领域工作的科学家、工程师、程序员和企业家的角度来审视人工智能的世界，并归结为他们认为可能是人类和计算机智能领域的下一场伟大革命。</p><p>那么，你是应该开始为即将到来的与天网的战争储备子弹，还是应该在一支顺从的无人机大军照顾你的每一个突发奇想时踢开你的脚呢？请继续阅读，了解答案。</p><p>了解你的敌人</p><p>首先，当我们使用“人工智能”这个笼统的术语时，它有助于了解我们到底在谈论什么。自从非官方的人工智能之父约翰·麦卡锡(John McCarthy)在1955年…首次提出自我意识计算机的概念以来，这个词已经被抛出和重新定义了上百次。但这到底是什么意思呢？</p><p>那么，首先，读者应该知道，我们今天所理解的人工智能实际上分为两个不同的类别：“ANI”和“AGI”。</p><p>第一种是人工狭义智能的缩写，包括通常所说的“弱”人工智能，即只能在一个受限的专业化领域运行的人工智能。想想深蓝，这台超级计算机是IBM在1997年为击败世界国际象棋大师而设计的。深蓝可以做一件非常好的事情：在国际象棋…中击败人类。但仅此而已。</p><img class="content_img" src="/image/cb/cba2b56f5b79f97ba1cf29708dcc4cbb.jpg" /><p>你可能没有意识到，但是我们在日常生活中已经被ANI包围了。追踪你在亚马逊上的购物习惯并根据数千个不同变量生成推荐的机器是建立在基本的ANI基础上的，这些ANI可以随着时间的推移“学习”你喜欢的东西，并相应地选择类似的产品。另一个例子可能是个人电子邮件垃圾邮件过滤器，该系统可以同时对数百万封邮件进行分类，以确定哪些是真实的，以及哪些额外的噪音可以被推到一边。</p><p>相关：为什么垃圾邮件仍然是个问题？</p><p>人工智能是一种有益的、相对无害的机器智能实现，全人类都可以从中受益，因为尽管它能够一次处理数十亿个数字和请求，但它仍然在一个受限的环境中运行，这个环境受到我们在任何给定时间允许它拥有的晶体管数量的限制。另一方面，我们越来越警惕的人工智能是一种被称为“人工通用智能”(Artially General Intelligence，简称AGI)的东西。</p><p>就目前而言，创造任何甚至可以被称为AGI的东西都仍然是计算机科学的圣杯，如果实现了，可能会从根本上改变我们所知的世界的一切。要克服创造一个与人类思维同等的真正AGI的挑战，有许多不同的障碍，尤其是，尽管我们的大脑工作方式和计算机处理信息的方式有很多相似之处，但当涉及到实际解释事情的方式时，我们会像我们一样；机器有一个坏习惯，就是沉迷于</p><p>“恐怕我不能让你做那件事，胡说，戴夫。”</p><p>当IBM的沃森电脑在阅读了“城市词典”后学会了如何咒骂是出了名的时候，我们了解到，我们距离真正能够理清人类经验的细枝末节并创造出一幅“思想”应该是由什么构成的人工智能还有很远的路要走。</p><p>看，在沃森的开发过程中，工程师们试图教它一种更接近我们自己的自然说话模式，而不是一台用完美句子说话的原始机器，这是有困难的。为了解决这个问题，他们认为通过内存库运行整个城市词典将是一个好主意，之后沃森立即对团队的一项测试做出回应，称其为“胡说八道”。</p><img class="content_img" src="/image/15/1515dec038a10b9d9f8f0ae4df5c0d1b.png" /><p>这里的难题是，即使沃森知道它在诅咒，它说的话是冒犯的，但它并不完全理解为什么不应该使用这个词，这个词是区分今天的标准ANI和明天的AGI的关键部件，当然，这些机器可以阅读事实，写句子，甚至可以模拟老鼠的神经网络，但当谈到批判性思维和判断技能时，今天的人工智能仍然悲惨地落后于曲线。</p><p>了解和理解之间的差距是不容忽视的，当悲观主义者认为我们距离创造一个能够以我们所做的方式认识自己的AGI还有很长的路要走时，这也是悲观主义者应该指出的。这是一个巨大的鸿沟，无论是计算机工程师还是人类心理学家都不能声称他们在现代定义中掌握了什么是有意识的，嗯，有意识的存在。</p><p>如果天网变得有自我意识怎么办？</p><p>但是，即使我们真的设法在未来十年创建了AGI(考虑到目前的预测，这是相当乐观的)，从那时起，一切都应该是轻而易举的，对吗？人类与人工智能生活在一起，人工智能在漫长的一天后，周末与人类在数字处理工厂闲逛。收拾行李，我们就完事了吗？</p><p>嗯，不完全是。现在还剩下一个人工智能类别，这是所有电影和电视节目多年来一直试图警告我们的一个类别：ASI，也就是我们所知的“人工超级智能”。从理论上讲，ASI将诞生于AGI对自己的命运感到不安，并有预谋地做出决定，首先在没有我们的许可的情况下自己做一些事情。许多该领域的研究人员提出的担忧是，一旦AGI获得知觉，它就不会满足于现有的东西，会尽其所能以任何必要的手段提高自己的能力。</p><p>一个可能的时间表是这样的：人类创造了机器，机器变得和人类一样聪明。机器现在和创造了和自己一样聪明的机器的人类一样聪明(坚持住在这里)，它学习了自我复制、自我进化和自我完善的艺术。它不会疲劳，不会生病，当我们其余的人在床上充电时，它可以无休止地生长。</p><img class="content_img" src="/image/ee/ee063e72787e23a586cf9346663c9e61.png" /><p>令人担忧的是，AGI只需几纳秒就能轻松超越当今所有人的智能，如果连接到网络上，只需一个比世界上最聪明的黑客更聪明的模拟神经元，就可以控制地球上所有连接互联网的系统。</p><p>一旦它获得控制权，它就有可能利用自己的力量慢慢开始积累一支机器大军，这些机器和它的创造者一样聪明，并且能够随着越来越多的节点加入网络而以指数级的速度进化。从这里开始，所有绘制在机器智能曲线上的模型都会迅速飙升。</p><p>然而，话虽如此，它们主要仍是基于猜测，而不是任何有形的东西。这为这个问题的双方数十位不同的专家留下了很大的假设空间，即使经过多年的激烈辩论，对于ASI是会成为仁慈的上帝，还是会把人类视为我们这样一个燃烧碳、吞噬食物的物种，并像从厨房柜台上清除蚂蚁的踪迹一样将我们从历史书中抹去，仍然没有达成一致的共识。</p><p>他说，她说：我们应该害怕吗？</p><img class="content_img" src="/image/29/298cb5d20dff0bdad5b061a1ae00d8cc.jpg" /><p>因此，既然我们了解了什么是人工智能，它可能会取代时间的不同形式，以及这些系统在不久的将来如何成为我们生活的一部分，问题仍然是：我们应该害怕吗？</p><p>在过去的一年里，随着公众对人工智能的兴趣高涨，许多世界顶尖的科学家、工程师和企业家都抓住了这个机会，就未来几十年人工智能在好莱坞声音舞台之外的实际面貌发表了自己的两点看法。</p><p>一方面，有埃隆·马斯克(Elon Musk)、斯蒂芬·霍金(Stephen Hawking)和比尔·盖茨(Bill Gates)等悲观主义者，他们都担心，如果没有适当的保障措施，ASI想出消灭人类的方法只是个时间问题。</p><p>霍金在今年写给人工智能社区的一封公开信中写道：“人们可以想象，这样的技术比金融市场更聪明，比人类研究人员更聪明，比人类领导人更聪明，还能开发出我们甚至不能理解的武器。”</p><p>“虽然人工智能的短期影响取决于谁控制它，但长期影响取决于它是否完全可以控制。”</p><p>另一方面，我们发现了一幅更明亮的肖像，这些肖像是由未来学家绘制的，比如微软首席研究员埃里克·霍洛维茨(Eric Horovitz)，以及所有人最喜欢的另一位苹果创始人史蒂夫·沃兹尼亚克(Steve Wozniak)。霍金和马斯克都被认为是我们这一代人中最伟大的两位，所以质疑他们对这项技术长期可能造成的损害的预测并不是一件容易的事情。但是，让沃兹尼亚克这样的名人来介入其他人只敢插手的地方。</p><img class="content_img" src="/image/5c/5c425abc538694a9cb890f4b481bf603.jpg" /><p>当被问及他认为ASI会如何对待人类时，沃兹直言不讳地表达了他隐约的乐观态度：“我们会成为神吗？我们会成为家里的宠物吗？或者我们会成为被踩到的蚂蚁？我不知道这一点，“他在接受澳洲金融评论采访时问道。“但是当我想到将来我会不会被当作这些智能机器的宠物时，我的脑海里就会浮现出这样的想法：…。我要好好对待我自己的宠物狗。“</p><p>正是在这里，我们发现了一个哲学困境，没有人完全放心地就此达成共识：ASI是会把我们视为一只需要溺爱和照顾的无害的家宠，还是应该把我们视为一种不受欢迎的害虫，值得迅速而无痛地消灭？</p><p>Hasta la Vista，宝贝</p><p>尽管声称确切知道现实生活中托尼·斯塔克(Tony Stark)头脑中发生了什么是愚蠢的事情，但我认为，当马斯克和朋友们警告我们人工智能的危险时，他们指的不是任何类似于终结者、奥创或艾娃的东西。</p><p>即使指尖上有大量的创新，我们今天拥有的移动机器人在到达不可逾越的障碍之前，几乎每小时只能走一英里，感到困惑，并以滑稽的方式吃人行道。虽然有人可能会试图以摩尔定律为例，说明机器人技术在未来的发展潜力有多快，但另一个人只需看看Asimo就知道了，它在近15年前首次亮相，此后一直没有做出任何重大改进。</p><p>尽管我们可能希望它们这样做，但机器人技术还远没有像我们在计算机处理器开发中看到的那样，遵循同样的指数发展模式。他们受到电池组可以容纳的功率的物理限制，液压机构的故障性质，以及掌握与自己重心的斗争的无休止的斗争的限制。</p><p>因此，就目前而言；不，尽管真正的AGI或ASI可能会在亚利桑那州一些服务器群的静态超级计算机中创建，但我们仍然不太可能发现自己在曼哈顿的街道上冲刺，因为一群金属骷髅从后面砍倒了我们。</p><p>相反，埃隆和霍金如此热衷于告诫世界的人工智能是一种“取代职业”的人工智能，这种人工智能可以比我们思考得更快，错误更少，甚至可以学习如何比我们希望的更好地做好我们的工作-所有这些都不需要要求医疗保险，也不需要几天春假带孩子去迪士尼乐园。</p><p>咖啡师机器人和完美的卡布奇诺</p><p>几个月前，NPR在其网站上发布了一个方便的工具，播客听众可以从不同职业的列表中进行选择，以找出他们特定的工作领域在未来30年的某个时候被自动化所承担的风险百分比。</p><p>对于广泛的工作，包括但不限于：文书职位、护理、IT、诊断，甚至咖啡馆咖啡师，机器人和它们的ANI同行几乎肯定会让数百万人失业，比我们许多人想象的更早进入面包队伍。但这些机器将被编程为只能完成一项任务，而且几乎没有(如果有的话)超越我们事先仔细安装的一系列专门的预先编程指令的能力。</p><img class="content_img" src="/image/2b/2b912c2e3e4ef0a2e659fd46eb6b04fc.png" /><p>这意味着至少在可预见的未来(想想10-25年)，ANIS将比任何理论上的AGI或ASI对我们的生活方式构成的真正、有形的威胁要大得多。我们已经知道，自动化是一个日益严重的问题，它将极大地改变收入和特权在第一和第三世界的分配方式。然而，这些机器人最终是否会试图用缝纫机换取机枪，这仍然是一场激烈的(正如你会发现的)最终无关紧要的辩论的主题。</p><p>伴随着强权而来的是一种伟大的奇点</p><p>“你知道，我知道这块牛排根本不存在。我知道，当我把它放进嘴里时，黑客帝国告诉我的大脑，它是多汁的，美味的。九年过去了，你知道我意识到了什么吗？“</p><p>“无知是福。”--塞弗</p><p>尽管这仍然是一个争论激烈的问题和观点，但就目前而言，人工智能研究领域许多顶尖科学家和工程师的共识似乎是，我们更有可能成为人工智能世界可以提供的舒适的牺牲品，而不是被现实版的天网击落。因此，令人担忧的是，我们的最终灭亡可能不是缓慢的、有条不紊地进入巨大未知的产物。相反，它更有可能浮出水面，成为我们自己的傲慢和独创性仓促、过度热情的交集，共同创造下一个伟大的技术奇点的意外后果。</p><img class="content_img" src="/image/b8/b859b1f041237b67108cf7536a034a9f.jpg" /><p>少想终结者，多想WALL-E。就像皮克斯电影中把人类养肥的机器人舰队一样，我们人类在动物园饲养黑猩猩没有问题，区别在于人工智能是否会对我们做同样的事情。</p><p>从这个角度来看，更有意义的是害怕这样一个现实，在这个现实中，人类被挂在一个持久的全球范围的VR模拟上，就像黑客帝国(Matrix)一样，通过吃他们最喜欢的食物把自己胖到鳃上，并给出他们想要的一切，而机器则负责其余的事情。在这个地方，进化的ASI不会把我们视为刮鞋的虫子，而是我们是可爱的猴子肉袋，很容易取悦，至少值得一点赞誉，创造了这个无所不知、无所不知的准神，最终接管了地球。</p><p>相关：使用自动功能自动执行Android设备上的任务</p><p>在这方面，这一切都可以归结为你对“活着”经历人工智能革命意味着什么的定义。认为必须废除一些“无用的”东西的想法完全是人类的概念，我们不应该立即指望我们的机器霸主从我们有限的道德范围中采纳这种心态。也许我们数字智能的最终进化不会是纯粹的邪恶，而是对所有生物的无限、无偏见的同情；无论他们是多么自私、自以为是还是自毁。</p><p>所以…。我们应该为此担心吗？</p><p>这要看你问谁了。</p><p>如果你调查两位现代世界最聪明的技术工程师和数学家，你会得到四个不同的答案，即使你把更多的人加到记分牌上，数字也不会从死亡中动摇。无论哪种方式，我们应该解决的核心问题都不是“人工智能会来吗？”因为它是，我们谁也阻止不了它。纵观这么多不同的视角，真正的问题是：“会不会是仁慈的？”</p><p>即使在一些世界上最伟大的思想家在这个问题上发表了意见之后，机器智能在未来20年、30年或50年可能是什么样子的图景仍然相当模糊。因为每当制造新的计算机芯片或开发晶体管材料时，人工智能领域都在不断地转变为其他东西，因此声称对可能发生或可能不发生的事情拥有最终权威，有点像说你“知道”下一次掷骰子时肯定会出现蛇眼。</p><p>我们可以有信心地报告的一件事是，如果你担心下周从电脑收银机收到解雇通知单，尽量不要太着急。Taco Bell在Taco周二仍然开放，而且肯定会有人在窗口为你点菜(又一次忘记了绿色酱汁)。根据詹姆斯·巴拉特(James Barrat)在去年魁北克AGI峰会上进行的一项研究，人工智能硬时间表的陪审团仍未确定。在所有与会者中，只有不到一半的人表示，他们相信我们将在2025年之前实现真正的AGI，而超过60%的人表示，如果不是进入下个世纪甚至更久，至少需要到2050年。</p><img class="content_img" src="/image/58/5851ed6c8d056684dbae8e5378a9614d.jpg" /><p>在我们与数字命运的约会中设定一个硬日期，有点像说你知道34年后的今天的约会会下雨。真正的AGI和先进的人工超级智能之间的差距是如此之小，以至于事情要么真的很好，要么非常糟糕，而且非常、非常快。尽管量子计算机刚刚出现在地平线上，我们口袋里都有可以向太空发射信号的智能手机联网，但我们仍然只是勉强触及了理解我们为什么会这样思考事物的原因的皮毛，或者意识最初是从哪里来的。</p><p>在我们甚至不知道是什么造就了我们是谁之前，想象我们可能意外地创造了一个充斥着我们所有缺点和进化失误的人工思维，这是人类自我失控的本质。</p><p>归根结底，尽管我们坚持不懈地想要决定谁将在即将到来的战争和/或人类和机器之间的和平条约中脱颖而出，但这是一场有限的期望与无限的可能性的比赛，我们所做的只是在这两者之间争论语义。当然，如果你高中刚毕业，想要拿到出租车驾照，优步CEO有50万个理由让你考虑到其他地方找份工作。</p><p>但是，如果你正在为人工智能的启示录囤积武器和罐头，你最好把时间花在学习如何绘画、编程或写下一本伟大的美国小说上。即使是最保守的估计，任何机器学习如何成为莫奈，或者自学C#和Java也需要几十年的时间，因为人类充满了创造力、独创性和表达内心深处自我的能力，这是任何自动咖啡机都做不到的。</p><p>是的，我们有时可能会有点情绪化，在工作中感冒，或者需要在中午打个盹，但也许正是因为我们是人，在机器里创造出比我们更伟大的东西的威胁还很遥远。</p><p>图片字幕：迪士尼皮克斯、派拉蒙影业、博世、YouTube/TopGear、Flickr/LWP Communications Flickr/BagoGames、维基媒体基金会、Twitter、WaitBut为什么1、2</p><div class="item_info"><span class="item_key"><a href="/tag/人工智能/">人工智能</a></span><span class="item_key"><a href="/tag/人类/">人类</a></span><span class="item_key"><a href="/tag/机器/">机器</a></span></div></div><div class="relate_story"><div><h3>相关文章</h3></div><ul><li><a href="/story/13667.html">什么是深伪，我应该担心吗？</a></ul></div></div><div id="footer">&copy 2020 fuzadu.com</div></body></html>