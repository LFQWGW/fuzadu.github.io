<!doctype html><html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>如何使用Bash从子reddit中抓取主题列表</title><link rel="stylesheet" href="/css.css"></head><body><div id="header"><a class="site_title" href="http://www.fuzadu.com">复杂度</a></div><div><div><h2>如何使用Bash从子reddit中抓取主题列表</h2></div><div class="content"><p>Reddit为每个子Reddit提供JSON提要。下面介绍如何创建一个Bash脚本，该脚本可以下载并解析任何您喜欢的子reddit中的帖子列表。这只是Reddit的JSON提要可以做的一件事。</p><p>安装Curl和JQ</p><p>我们将使用cURL从Reddit获取JSON提要，并使用JQ解析JSON数据并从结果中提取我们需要的字段。在Ubuntu和其他基于Debian的Linux发行版上使用apt-get命令安装这两个依赖项。在其他Linux发行版上，请改用发行版的包管理工具。</p><code>sudo apt-get install curl jq</code><p>从Reddit获取一些JSON数据</p><p>让我们看看数据馈送是什么样子。使用cURL从MildlyInteresting subreddit获取最新帖子：</p><code>curl -s -A “reddit scraper example” https://www.reddit.com/r/MildlyInteresting.json</code><p>注意URL：-s之前使用的选项如何强制curl在静默模式下运行，这样我们就看不到任何输出，除了来自Reddit服务器的数据。下一个选项和紧随其后的参数-A“reddit scillper example”设置一个自定义用户代理字符串，该字符串帮助Reddit识别访问其数据的服务。Reddit API服务器根据用户代理字符串应用速率限制。设置自定义值将导致Reddit将我们的速率限制与其他呼叫者分开，并降低我们收到HTTP 429速率限制超出错误的机会。</p><p>输出应该填满终端窗口，如下所示：</p><img class="content_img" src="/image/f8/f88e9402a40c2d1e7f39a2092c45af2c.png" /><p>输出数据中有很多字段，但我们只对标题、固定链接和URL感兴趣。您可以在Reddit的API文档页面上看到类型及其字段的详尽列表：https://github.com/reddit-archive/reddit/wiki/JSON</p><p>从JSON输出提取数据</p><p>我们希望从输出数据中提取标题、固定链接和URL，并将其保存到制表符分隔的文件。我们可以使用sed和grep等文本处理工具，但是我们可以使用另一种理解JSON数据结构的工具，称为JQ。在我们的第一次尝试中，让我们使用它对输出进行美观的打印和颜色编码。我们将使用与前面相同的调用，但这一次，通过管道将输出传递给JQ，并指示它解析和打印JSON数据。</p><code>curl -s -A “reddit scraper example” https://www.reddit.com/r/MildlyInteresting.json | jq .</code><p>请注意该命令后面的句点。该表达式简单地解析输入并按原样打印。输出看起来格式和颜色编码都很好：</p><img class="content_img" src="/image/e9/e9addf4553e0488ead4b6bb11cb809ca.png" /><p>让我们检查一下从Reddit返回的JSON数据的结构。根结果是一个包含两个属性的对象：Kind和Data。后者拥有一个名为Child的属性，其中包括到该子reddit的帖子数组。</p><p>数组中的每一项都是一个对象，该对象还包含称为Kind和Data的两个字段。我们要获取的属性在数据对象中。JQ期望一个可应用于输入数据的表达式，并产生所需的输出。它必须按照数组的层次结构和成员身份描述内容，以及应该如何转换数据。让我们使用正确的表达式再次运行整个命令：</p><code>curl -s -A “reddit scraper example” https://www.reddit.com/r/MildlyInteresting.json | jq ‘.data.children | .[] | .data.title, .data.url, .data.permalink’</code><p>输出在各自的行上分别显示标题、URL和固定链接：</p><img class="content_img" src="/image/d9/d9ee97b0ea40c7bd8d57a6d70c4b8855.png" /><p>让我们深入了解一下我们调用的njq命令：</p><code>jq ‘.data.children | .[] | .data.title, .data.url, .data.permalink’</code><p>此命令中有三个表达式，由两个管道符号分隔。每个表达式的结果都会传递给下一个表达式进行进一步计算。第一个表达式过滤掉除Reddit列表数组之外的所有内容。此输出通过管道传递到第二个表达式中，并强制传递到一个数组中。第三个表达式作用于数组中的每个元素，并提取三个属性。更多关于JQ及其表达式语法的信息可以在JQ官方手册中找到。</p><p>将所有这些放在一个脚本中</p><p>让我们将API调用和JSON后处理放在一个脚本中，该脚本将生成一个包含我们需要的帖子的文件。我们将添加对从子reddit获取帖子的支持，而不仅仅是/r/MildlyInteresting。</p><p>打开您的编辑器并将此代码段的内容复制到名为scrapl-reddit.sh的文件中</p><code>#!/bin/bash

if [ -z "$1" ]
  then
    echo "Please specify a subreddit"
    exit 1
fi

SUBREDDIT=$1
NOW=$(date +"%m_%d_%y-%H_%M")
OUTPUT_FILE="${SUBREDDIT}_${NOW}.txt"

curl -s -A "bash-scrape-topics" https://www.reddit.com/r/${SUBREDDIT}.json | \
        jq '.data.children | .[] | .data.title, .data.url, .data.permalink' | \
        while read -r TITLE; do
                read -r URL 
                read -r PERMALINK
                echo -e "${TITLE}\t${URL}\t${PERMALINK}" | tr --delete \" >> ${OUTPUT_FILE}
        done
</code><p>此脚本将首先检查用户是否提供了subreddit名称。如果不是，它将退出，并显示一条错误消息和一个非零返回代码。</p><p>接下来，它将存储第一个参数作为subreddit名称，并构建一个带日期戳的文件名，以保存输出。</p><p>当使用自定义头和要抓取的subreddit的URL调用curl时，操作开始。输出通过管道传输到JQ，在那里被解析并缩减为三个字段：Title、URL和PermalLink。这些行一次读取一行，并使用READ命令保存到一个变量中，所有这些行都在WHILE循环中，该循环将继续执行，直到没有更多的行可读。内部While块的最后一行回显由制表符分隔的三个字段，然后通过tr命令对其进行管道传输，以便可以去掉双引号。然后将输出追加到文件中。</p><p>在我们可以执行此脚本之前，我们必须确保它已被授予执行权限。使用dchmod命令将以下权限应用于该文件：</p><code>chmod u+x scrape-reddit.sh</code><p>最后，使用子reddit名称执行脚本：</p><code>./scrape-reddit.sh MildlyInteresting</code><p>在同一目录中生成输出文件，其内容如下所示：</p><img class="content_img" src="/image/2f/2f7978d4a8842059621bbac36f9edebd.png" /><p>每行包含我们后面的三个字段，用制表符分隔。</p><p>走得更远</p><p>Reddit是一个有趣的内容和媒体的金矿，所有这些都可以通过它的JSON API轻松访问。现在您已经有了访问此数据并处理结果的方法，您可以执行以下操作：</p><p>
从/r/WorldNews抓取最新的标题，然后使用Notify-Send将它们发送到您的桌面。
将/r/DadJokes中最好的笑话集成到您的系统的每日消息中。
从/r/aww获取今日最佳图片，并将其设置为您的桌面背景</p><p>使用提供的数据和您系统上的工具，所有这些都是可能的。黑客快乐！</p><div class="item_info"><span class="item_key"><a href="/tag/reddit/">reddit</a></span><span class="item_key"><a href="/tag/数据/">数据</a></span><span class="item_key"><a href="/tag/输出/">输出</a></span></div></div><div class="relate_story"><div><h3>相关文章</h3></div><ul><li><a href="/story/14356.html">什么是Reddit Gold，您为什么想要它？</a><li><a href="/story/13381.html">什么是一次性Reddit帐户，我如何创建一个？</a><li><a href="/story/11156.html">如何让Reddit变得不那么差劲</a><li><a href="/story/9028.html">如何通过Res最大限度地利用Reddit</a><li><a href="/story/3769.html">如何在路由器级别阻止网站进行网络范围过滤</a></ul></div></div><div id="footer">&copy 2020 fuzadu.com</div></body></html>